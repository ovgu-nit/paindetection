---
title: Multi modal AI based pain detection
description: "Development of a robust, reliable and multimodal AI system for the pain quantification"
background: /assets/theme/images/header-img.png
permalink: /projects/project_MM/
---

{: .alert .alert-warning}
 
![image](/paindetection_nit/assets/theme/images/VAS_BPS.png)

## Motivation

Previous research works in the NIT working group resulted in many advacements and ai-based methods in the area of pain detection. However, recent advacements in machine learning and especially deep learning such as the usage of attention in foundation models allow to even improve the accuracy and the robustness pain detection. Further, since pain databases such as BioVid and X-ITE use a self report of the experienced pain as their ground truth, the resulting AI-based models could not be applicable to such patients that are unable to communicate/self-report their pain. Thus, it is nessecary to construct a second ground truh label for the X-ITE database, that is completely based on an expert report of the percieved pain based on the expression of the pain.

## Goals

The aim of this project is to develop a robust and reliable pain detection system. This shall be achived by first improving on the previous findings of the NIT research works, which are still state of the art in pain detection. This can be achieved by applying new machine learning technologies to previous findings on the BioVid and X-ITE database and evaluating those again the state of the art models. Further an extensive study of the resulting models on the performance on the self-report against the new expert report labels of X-ITE should be conducted. Together with the real world data recorded in the postoperative IMC project, these models should then result in a robust pain detection system.

 
![image](/paindetection_nit/assets/theme/images/Mindmap_AI_MM.png)
